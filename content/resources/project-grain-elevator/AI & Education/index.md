---
bookFlatSection: false
bookHidden: false
bookToC: true
title: "+ AI"
type: docs
draft: false
---

<small>
“At a fundamental level, the development of AI requires us to consider the purpose of education.” 

— Corinne Hyde

“Mechanical devices that separate the act of writing from the hand of the writer have provoked fascination and dismay since the early days of the Industrial Revolution. Machines that resembled humans and appeared to write on their own delighted the royal courts of Europe in the late eighteenth century. Like music boxes or cuckoo clocks, these automata executed preprogrammed tasks. But they proved to be particularly captivating because the task they performed—handwriting—was thought to be uniquely human. An automata’s ability to hold a pen, ink it, and write phrases in cursive demonstrated its inventor’s mechanical ingenuity. At the same time, by mutely mimicking a process associated with self-reflection and individuality, automata made for absurd parodies of Enlightenment values.”

— “Writing Machines,” *[Ghosts in the Machine](https://a.co/d/gwqtsLv)* 
 
 "Being a person is not a goal that can be achieved but a purpose that must be sustained."
 
— Martin Hagglund, *This Life*

</small> 

---

# AI and Writing

GAI is both a symptom and an acceleration of a cultural trend that considers education solely in transactional terms. I am struck by Cao and Dede’s thoughts on this point:

> “An education that is heavily focused on products reduces learning to a transaction, exchanging a product for a grade, rather than providing a transformative human experience. Learning is much more than generating a product; in fact, the essence of learning is in the process – the journey rather than the destination. Learning to write is not primarily about producing a well-structured piece of text but about developing the capacity to organize one’s ideas, connect these to others’ ideas, analyze claims, synthesize insights, and fulfill our fundamental need to communicate with and learn from others. Similarly, learning a new language is much more than being able to speak in that tongue; bilingualism is about learning another style of thinking, taking on a different cultural identity, and embodying an alternative way of being and living in the world” (3).

It bears emphasizing that education is not merely the production of assignments submitted to authorities, or the collection of diplomas—it is instead the gaining of the ability to think clearly, to argue effectively, to discover one's own beliefs, to make connections, to communicate, to value, suspend judgment and allow ourselves to truly become vulnerable to new ideas through patient, genuine listening and study. We are talking about nothing less than the growth, the becoming, of a single, unique human life. 

# Writing in the Age of Mechanical Production

Before we consider using any new tool or technology, we should ask ourselves whether it contributes to the overall purpose of education. While Generative AI certainly has a place in many fields and disciplines in varying degrees (and I'm genuinely excited about many aspects of it myself), I believe that it is fundamentally in conflict with the goals of the writing classroom. 

My sense has always been that the writing classroom is the best place to develop a host of important skills, including the development of critical thinking, metacritical analysis (thinking about our thinking), information literacy, creativity, communication skills, and various research competencies. These abilities lie at the heart of education; they are the tools and practices of freedom (from the Latin *liberalis* ('free') and *ars* ('practice or art').  

An overreliance on AI tools to complete tasks that we would normally describe as "thinking" or "analysis" or "articulation," will have a tremendously negative affect on our development as individuals, on the process of becoming that is primarily driven by education. Used improperly, I fear these new technologies may actually result in a new form of disability. If we use these tools merely to get answers, not encourage us to develop understanding or skill; or if we allow them to generate a mere appearance of thought and expression, rather than its substance, then what will become of us?

As [Joshua Thorpe](https://wonkhe.com/blogs/the-real-risk-of-generative-ai-is-a-crisis-of-knowledge/) argues, 

> "\[AI] tools suddenly make it really easy to do all kinds of things, very quickly, that used to be hard and slow. Many of these things used to be essential to the *intrinsic value* of university work—planning, decision-making, struggling, searching, assessing sources, grappling with difficult texts, and learning to accept the discomfort of uncertainty. AI tools remove problems. But some of the problems they remove are useful to have and to solve as a human. Students will find it really difficult to distinguish between what problems are good to solve quickly with AI, and which problems are more valuable to solve themselves.” 

Among the many problems I believe you should solve yourself if you are interested in being intelligent and, you know, a human being: 

- reading, 
- parsing the meaning of texts and other artifacts, 
- [inventio](https://en.wikipedia.org/wiki/Inventio) (discovering your own arguments and ideas), 
- research, 
- evaluating sources of information, 
- planning and organizing writing, revising, and evaluating feedback from others on your writing. 

AI can disrupt or replace many or all of these processes; the consequences of doing so, however, are exceedingly grim.     

Writing (and the struggle to do so) is one of the best ways to discover ideas and thoughts. Many imagine that writing is about 1) getting a clear idea in our heads and then 2) articulating that clear idea using words on a page. As scholar David Galbraith argues, “The content that we write about is not pre-stored, waiting only on us to decide how best to deploy it, but is instead something that is constituted as we write. And the process of constituting this content is not straightforward but is instead a matter of trying to capture our understanding as it unfolds in the text. Writing, to use T. S. Eliot’s phrase, is a raid on the inarticulate, and it is integrating this process with the more strategic aspects of writing that is the work of writing.” (Galbraith, "Raiding," 238). However, writing is often more magical than mechanical. The writing seemingly conjures these things out of nothing, often revealing surprising beliefs or ideas that we did not know we held. As the novelist E.M Forster once quipped: "How can I know what I think until I see what I say?" The common experience of this phenomenon points to there being something special about writing as a tool for discovery—a way of making sense of the world, and learning about ourselves, our values, and commitments. However, this all seems something that could very well be deeply compromised if we develop a reliance on GAI. 

I’ve also been poking about at earlier Writing Studies scholarship in the 80s and 90s, when the “Write to Learn” movement was making strides. A lot of the research in the folders concerns some of this early work which intersected with early cognitive science and psychology. I think the WTL movement may be traced back to Anne Gere’s *Roots in the Sawdust* (1985), where she argues: "Writing is uniquely suited to foster abstract thought. As cognitive psychologists and composition theorists have noted, writing is an extremely focused activity which simultaneously involves hand, eye, and brain. The linearity of writing, one word after the other, leads to more coherent and sustained thought than thinking or speaking. The physical limitations imposed on writers make writing a slow process (slow relative to thinking or talking), and this slowness seems to free some parts of the brain for the discoveries so common among writers" (qtd. in Ackerman 349).


---

Before we consider using any new tool or technology, we should ask ourselves whether it contributes to the overall purpose of our education. While Generative AI (GAI) certainly has a place in many fields and disciplines in varying degrees, I believe that it is fundamentally in conflict with the goals of the writing classroom. These goals include the development of critical thinking, metacritical analysis (thinking about our thinking), information literacy, and research skills. These new technologies are designed to give answers, not encourage us to develop understanding or skill. 

One benefit from the advent of these AI tools, however, is that it allows us to stop and consider, perhaps for the first time, the actual purpose of education and, in particular, of learning to write. Of what use is writing for ourselves? Of what use is learning to write? If the essay that you turn in is just a product that you need to submit in order to get a reward, then using GAI to complete the assignment makes perfect sense. This is a symptom of a larger pattern of thought that imagines the whole of education as a series of transactions, the delivery of products in exchange for a grade or promotion. You can certainly do that. Many do. However, as As Lydia Cao and Chris Dede write,

> An education that is heavily focused on products reduces learning to a transaction, exchanging a product for a grade, rather than providing a transformative human experience. Learning is much more than generating a product; in fact, the essence of learning is in the process – the journey rather than the destination. Learning to write is not primarily about producing a well-structured piece of text but about developing the capacity to organize one’s ideas, connect these to others’ ideas, analyze claims, synthesize insights, and fulfill our fundamental need to communicate with and learn from others. (3)

What is the purpose of education and learning? Learning to write, and writing to learn, are perhaps the best way to accomplish several central goals of education. These goals include the development of critical thinking, metacritical analysis (thinking about our thinking), information literacy, creativity, instincts, communication skills, and research competencies. These new technologies are designed to give answers, not encourage us to develop understanding or skill—things that are likely to become even more valuable in the future. Please know that these are not the ravings of some grumpy, out-of-touch old man. I have *reasons*.  

As Lydia Cao and Chris Dede write, "Learning is much more than generating a product; in fact, the essence of learning is in the process – the journey rather than the destination. Learning to write is not primarily about producing a well-structured piece of text but about developing the capacity to organize one’s ideas, connect these to others’ ideas, analyze claims, synthesize insights, and fulfill our fundamental need to communicate with and learn from others." These goals include the development of critical thinking, metacritical analysis (thinking about our thinking), information literacy, creativity, instincts, communication skills, and research competencies. These new technologies are designed to give answers, not encourage us to develop understanding or skill—things that are likely to become even more valuable in the future. Please know that these are not the ravings of some grumpy, out-of-touch old man. I have *reasons*.  

Until quite recently, when we imagined the technolgical future, we conjured images of androids that resemble the Boston Dynamic creatures out in fields; clutching spades, powered by sunlight, the robots meticulously tending to potatoes and melons and corn; carefully eliminating pests by hand so that no pesticides will ever enter the food system, and plucking the food at the perfect moment of ripeness, placing it in mechanized bins that cart the goods to a factory, also manned by robots who wash and prepare and can our food. Thereafter shipped to distribution centers where our personal robots will go do our shopping for us. At home, our personal domestic robots will charge themselves in our basements each night, and when detecting our wakening, will spring to life and cook us eggs and the busy itself cleaning our houses and weeding our yards. It was, in short, a vision of life freed of all unwanted physical labor and drudgery: the cleaning of bathtubs and toilets, shopping for food, preparing meals, mowing lawns. With technology, we could finally inherit the world John Maynard Keynes famously imagined in 1930 in "Economic Possibilities for our Grandchildren," where effiencies in production and compoud interest carried from the past would relieve humans from almost all need to labor. Without this burden we could maximize our precious time here on earth by living lives of leisure: discovering our potential, exploring our humanity, travelling, thinking, creating art, conteplating beauty. But the new world that appears to be dawning here is the inversion of that dream. Our robot surrogates obviate thinking and humanizing efforts so that we can find a better place in the system of labor that exploits us. We seem instead intent on creating a world free of mental effort and creation: the slow work of close reading and analysis, creation, inspiration and communication.

In many ways this is beneficial to students because it requires a shift away from a product-based, transactional model of education, to a process-based form of education rooted in inquiry and intrinsic motivation. As Lydia Cao and Chris Dede write,

> An education that is heavily focused on products reduces learning to a transaction, exchanging a product for a grade, rather than providing a transformative human experience. Learning is much more than generating a product; in fact, the essence of learning is in the process – the journey rather than the destination. Learning to write is not primarily
about producing a well-structured piece of text but about developing the capacity to organize one’s ideas, connect these to others’ ideas, analyze claims, synthesize insights, and fulfill our fundamental need to communicate with and learn from others. Similarly, learning a new language is much more than being able to speak in that tongue; bilingualism is about learning another style of thinking, taking on a different cultural identity, and embodying an alternative way of being and living in the world. (3)

How
But this does take some doing if you were invested in deliverable objects like an end-of-term final essay for student assessment. 


Although I don't lose any sleep at night worrying about [sentient robots enslaving mankind](https://www.nytimes.com/2021/02/13/technology/slate-star-codex-rationalists.html), there is a much more subtle threat that has begun to loom large in my imagination and take up a great deal of my thought life. I think it has a much more realistic chance of ending humanity as we know it. And it is perhaps all the more terrifying because it will be a form of what Rob Nixon calls "slow violence": a form of violence "that occurs gradually and out of sight, a violence of delayed destruction that is dispersed across time and space, an attritional violence that is typically not viewed as violence at all" (2). Since our media environments are biased toward sensational spectacles of destruction, and humans tend to hysterically inflate things they fear, cultural anxieties about new technologies have frequently been articulated as exaggerated, dramatic ends to humanity. But to my mind, the threat from AI is unlikely to take the form of an apocalypse; I think it will more likely result in the slow, insensible erosion of the characteristics and abilities that we've traditionaly thought of as defining the human. 

1. Remove anxieties about grading, which may lead students to lose trust in themselves and their own abilities.
2. "No one plagiarizes their diary entries." Emphasize writing and thinking assignments that generate *intrinsic* motivation, rather than use extrinsic ones.
3. Eliminate any elements that suggest education-as-product rather than education-as-process: the journey, not the destination.
4. 


# Prosthetic Gods

> Long ago [man] formed an ideal conception of omnipotence and omniscience which he embodied in his gods. To these gods he attributed everything that seemed unattainable to his wishes, or that was forbidden to him. One may say, therefore, that these gods were cultural ideals. Today he has come very close to the attainment of this ideal, he has almost become a god himself. Only, it is true, in the fashion in which ideals are usually attained according to the general judgment of humanity: not completely, in some respects not at all, in others only half way. Man has, as it were, become a kind of prosthetic God. When he puts on all his auxiliary organs he is truly magnificent; but those organs have not grown on to him and they still give him much trouble at times. . . . Future ages will bring with them new and probably unimaginably great advances in this field of civilization and will increase man’s likeness to God still more. But in the interests of our investigations, we will not forget that present-day man does not feel happy in his Godlike character.
>
> — Freud, *Civilization and Its Discontents* 

Technology shapes us, often as much as we shape it. As Freud remarks, our technological devices augment us with almost superhuman powers: a telephone amplfies our voice so that I can be heard thousands of miles away; a telescope gives us a view into the deepest corner of the universe. As we merge with technology Before we consider using any new tool or technology that is designed to augment or improve our lives, we should pause and reflect on how this tool might alter us. 

Certainly, we've all sweated out a final paper, trying to change our fonts or fiddle with margins so that we can make the required page count. Or we've been paralyzed by writer's block as we tried to come up with an idea for an essay. Or we struggled with finding quality sources for a research project. It doesn't feel like it at the time, but the entire point of this sort of work is to struggle, and fail, and try again. That's where the learning happens; that's where skills are forged.

- What is the point of these assignments? The purpose that we've all forgotten because we imagine these things as hoops that we must jump through, or tasks that we must complete so that we can be give our reward of a grade and move on to the next task. This is an understanding of school, education, assignments, as a series of transactions. But why are we doing these assignments in the first place? Just to make kids dance a dance for us, like a bunch of authoritarian weirdos before passing them along to another one of our tribe? Is education like fraternity hazing? 


