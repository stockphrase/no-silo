---
bookFlatSection: false
bookHidden: false
bookToC: true
title: "+ On Generative AI"
type: docs
draft: false
weight: 3
---

# On Generative AI and Writing

---

While Generative AI certainly has a place in many fields and disciplines (and I’m genuinely excited about aspects of it myself), I believe that it is fundamentally in conflict with the goals of the writing classroom.

My sense has always been that the writing classroom is the best place to develop a host of important skills and abilities, including critical thinking, metacritical analysis (thinking about our thinking), information literacy, creativity, communication skills, and various research competencies. 

An overreliance on AI tools to complete tasks that we would normally describe as “thinking” or “analysis” or "research" will have a tremendously negative effect on our development as individuals. If we use these tools merely to get answers, not encourage us to develop understanding or skill; or if we allow them to generate a mere appearance of thought and expression, rather than its substance, then what will become of us? I mean this literally: what will we be?

As you will understand the more you get to know me, I view learning to write as a fundamental tool of liberty. In fact, the liberal arts (*artes liberales*) literally mean the arts or tools of freedom. Learning to articulate your ideas, to shape your reasoning, to analyze, to question, to research, to use evidence—to learn to write, in other words, is the foundational experience of education. I share this view with one of the founding scholars of composition studies, I. A. Richards. As [Ann Berthoff explains](https://www.jstor.org/stable/3885439):

> [Richard's] pedagogical inventions are all conceived of as ways and means of placing the process of composing, of forming, in the control of the meaning-maker [the student]. By their means, IAR gave form to his passionate conviction that reading and writing are moral concerns and that what we do in teaching them . . . has important political dimensions. Control means the ability to exercise choice. Just as interpretation in the classroom is a model for all acts of mind, so learning to choose words and deciding the way we want them to work "can become an introduction to the theory of all choices." Gains in literacy are therefore gains in human freedom (197).

I find this idea inspiring and persuasive. And it is a stark warning about the possible outcomes from misusing this new technology. 

Consider that it only makes sense to cut corners with an AI tool so long as we imagine education as a kind of economy rooted in the exchange of educational products that receive compensation in the form of grades. However, this is an impoverished vision of the purpose of education. I am struck by [Lydia Cao and Chris Dede's](https://bpb-us-e1.wpmucdn.com/websites.harvard.edu/dist/a/108/files/2023/08/Cao_Dede_final_8.4.23.pdf) thoughts on this point:

> An education that is heavily focused on products reduces learning to a transaction, exchanging a product for a grade, rather than providing a transformative human experience. Learning is much more than generating a product; in fact, the essence of learning is in the process – the journey rather than the destination. Learning to write is not primarily about producing a well-structured piece of text but about developing the capacity to organize one’s ideas, connect these to others’ ideas, analyze claims, synthesize insights, and fulfill our fundamental need to communicate with and learn from others. 

Echoing this point about the process of education, Ted Chiang [offers a perfect metaphor](https://www.newyorker.com/culture/the-weekend-essay/why-ai-isnt-going-to-make-art) to explain the problems with relying on GAI:

> [T]eachers don’t ask students to write essays because the world needs more student essays. The point of writing essays is to strengthen students’ critical-thinking skills; in the same way that lifting weights is useful no matter what sport an athlete plays, writing essays develops skills necessary for whatever job a college student will eventually get. Using ChatGPT to complete assignments is like bringing a forklift into the weight room; you will never improve your cognitive fitness that way.

Some of the problems and struggles that come with education are actually things that we shouldn't try to get rid of. Side-stepping these difficulties renders the entire enterprise of education pointless. [Joshua Thorpe](https://wonkhe.com/blogs/the-real-risk-of-generative-ai-is-a-crisis-of-knowledge/) explains:

>[AI] tools suddenly make it really easy to do all kinds of things, very quickly, that used to be hard and slow. Many of these things used to be essential to the intrinsic value of university work—planning, decision-making, struggling, searching, assessing sources, grappling with difficult texts, and learning to accept the discomfort of uncertainty. AI tools remove problems. But some of the problems they remove are useful to have and to solve as a human. Students will find it really difficult to distinguish between what problems are good to solve quickly with AI, and which problems are more valuable to solve themselves.

I would argue that Thorpe doesn't go quite far enough: not only are many of these problems and difficulties "useful to have and to solve as a human," these struggles are *precisely the things that make us human and allow us to become more humane*. Among the many problems I believe you should solve yourself if you are interested in being intelligent and growing as a human being:

- reading widely,
- interpreting the meaning of texts and other artifacts,
- *[inventio](https://en.wikipedia.org/wiki/Inventio)* (discovering your own arguments and ideas),
- research/inquiry,
- evaluating sources of information,
- planning and organizing writing, 
- drafting writing,
- revising your writing (and evaluating feedback from others on your writing).

AI can disrupt or replace many or all of these processes; the consequences of doing so, however, are exceedingly grim. 

---
